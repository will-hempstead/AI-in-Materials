{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2123c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as Fy\n",
    "from torch.utils import data\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "from os.path import exists\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_smiles\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.models import AttentiveFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5be55b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the torch geometric from_smiles function\n",
    "# you can edit the rdkit features included \n",
    "# default features are 9 - i will try to augment this\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch_geometric\n",
    "\n",
    "x_map: Dict[str, List[Any]] = {\n",
    "    'atomic_num': list(range(0, 119)),\n",
    "    'chirality': [\n",
    "        'CHI_UNSPECIFIED', 'CHI_TETRAHEDRAL_CW', 'CHI_TETRAHEDRAL_CCW',\n",
    "        'CHI_OTHER', 'CHI_TETRAHEDRAL', 'CHI_ALLENE', 'CHI_SQUAREPLANAR',\n",
    "        'CHI_TRIGONALBIPYRAMIDAL', 'CHI_OCTAHEDRAL',\n",
    "    ],\n",
    "    'degree': list(range(0, 11)),\n",
    "    'formal_charge': list(range(-5, 7)),\n",
    "    'num_hs': list(range(0, 9)),\n",
    "    'num_radical_electrons': list(range(0, 5)),\n",
    "    'hybridization': [\n",
    "        'UNSPECIFIED', 'S', 'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'OTHER',\n",
    "    ],\n",
    "    'is_aromatic': [False, True],\n",
    "    'is_in_ring': [False, True],\n",
    "    'valence': list(range(0, 8)),\n",
    "    'num_rings': list(range(0, 10)),\n",
    "    'implicit_valence': list(range(0, 7)),\n",
    "    'explicit_valence': list(range(0, 8)),\n",
    "    'mass': list(range(0, 250)),  # Discretized atomic mass\n",
    "    'isotope': list(range(0, 10)),\n",
    "    'ring_sizes': list(range(0, 10)),  # Smallest ring size\n",
    "}\n",
    "\n",
    "e_map: Dict[str, List[Any]] = {\n",
    "    'bond_type': [\n",
    "        'UNSPECIFIED',\n",
    "        'SINGLE',\n",
    "        'DOUBLE',\n",
    "        'TRIPLE',\n",
    "        'QUADRUPLE',\n",
    "        'QUINTUPLE',\n",
    "        'HEXTUPLE',\n",
    "        'ONEANDAHALF',\n",
    "        'TWOANDAHALF',\n",
    "        'THREEANDAHALF',\n",
    "        'FOURANDAHALF',\n",
    "        'FIVEANDAHALF',\n",
    "        'AROMATIC',\n",
    "        'IONIC',\n",
    "        'HYDROGEN',\n",
    "        'THREECENTER',\n",
    "        'DATIVEONE',\n",
    "        'DATIVE',\n",
    "        'DATIVEL',\n",
    "        'DATIVER',\n",
    "        'OTHER',\n",
    "        'ZERO',\n",
    "    ],\n",
    "    'stereo': [\n",
    "        'STEREONONE',\n",
    "        'STEREOANY',\n",
    "        'STEREOZ',\n",
    "        'STEREOE',\n",
    "        'STEREOCIS',\n",
    "        'STEREOTRANS',\n",
    "    ],\n",
    "    'is_conjugated': [False, True],\n",
    "}\n",
    "\n",
    "\n",
    "def from_rdmol(mol: Any, use_3d:bool=False) -> 'torch_geometric.data.Data':\n",
    "    r\"\"\"Converts a :class:`rdkit.Chem.Mol` instance to a\n",
    "    :class:`torch_geometric.data.Data` instance.\n",
    "\n",
    "    Args:\n",
    "        mol (rdkit.Chem.Mol): The :class:`rdkit` molecule.\n",
    "    \"\"\"\n",
    "    from rdkit import Chem\n",
    "\n",
    "    from torch_geometric.data import Data\n",
    "\n",
    "    assert isinstance(mol, Chem.Mol)\n",
    "\n",
    "    xs: List[List[int]] = []\n",
    "    pos: List[List[float]] = []\n",
    "\n",
    "    for atom in mol.GetAtoms():\n",
    "        row: List[int] = []\n",
    "\n",
    "        # Original features\n",
    "        row.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "        row.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "        row.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "        row.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "        row.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "        row.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "        row.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "        row.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "        row.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "        \n",
    "        # New features\n",
    "        row.append(min(mol.GetRingInfo().NumAtomRings(atom.GetIdx()), 9))\n",
    "        row.append(x_map['valence'].index(atom.GetTotalValence()))\n",
    "        row.append(x_map['implicit_valence'].index(atom.GetImplicitValence()))\n",
    "        row.append(x_map['explicit_valence'].index(atom.GetExplicitValence()))\n",
    "        row.append(min(x_map['mass'].index(int(atom.GetMass())), 249))\n",
    "        row.append(min(atom.GetIsotope(), 9))\n",
    "        \n",
    "        # Smallest ring size this atom is in (0 if not in ring)\n",
    "        ring_info = mol.GetRingInfo()\n",
    "        atom_rings = ring_info.AtomRings()\n",
    "        ring_sizes = [len(ring) for ring in atom_rings if atom.GetIdx() in ring]\n",
    "        smallest_ring = min(ring_sizes) if ring_sizes else 0\n",
    "        row.append(min(smallest_ring, 9))\n",
    "        \n",
    "        xs.append(row)\n",
    "        \n",
    "        if use_3d:\n",
    "            conf = mol.GetConformer()\n",
    "            atom_pos = conf.GetAtomPosition(atom.GetIdx())\n",
    "            pos.append([atom_pos.x, atom_pos.y, atom_pos.z])\n",
    "    \n",
    "    x = torch.tensor(xs, dtype=torch.long).view(-1, 16)\n",
    "\n",
    "\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():  # type: ignore\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        e = []\n",
    "        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n",
    "        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n",
    "        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n",
    "\n",
    "        edge_indices += [[i, j], [j, i]]\n",
    "        edge_attrs += [e, e]\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices)\n",
    "    edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n",
    "\n",
    "    if edge_index.numel() > 0:  # Sort indices.\n",
    "        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n",
    "        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n",
    "\n",
    "    if use_3d and pos:\n",
    "        pos_tensor = torch.tensor(pos, dtype=torch.float)\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, pos=pos_tensor)\n",
    "    else:\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "\n",
    "def from_smiles(\n",
    "    smiles: str,\n",
    "    with_hydrogen: bool = False,\n",
    "    kekulize: bool = False,\n",
    "    use_3d: bool = False,\n",
    ") -> 'torch_geometric.data.Data':\n",
    "    r\"\"\"Converts a SMILES string to a :class:`torch_geometric.data.Data`\n",
    "    instance.\n",
    "\n",
    "    Args:\n",
    "        smiles (str): The SMILES string.\n",
    "        with_hydrogen (bool, optional): If set to :obj:`True`, will store\n",
    "            hydrogens in the molecule graph. (default: :obj:`False`)\n",
    "        kekulize (bool, optional): If set to :obj:`True`, converts aromatic\n",
    "            bonds to single/double bonds. (default: :obj:`False`)\n",
    "    \"\"\"\n",
    "    from rdkit import Chem, RDLogger\n",
    "    from rdkit.Chem import AllChem\n",
    "\n",
    "    RDLogger.DisableLog('rdApp.*')  # type: ignore\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if mol is None:\n",
    "        mol = Chem.MolFromSmiles('')\n",
    "    if with_hydrogen:\n",
    "        mol = Chem.AddHs(mol)\n",
    "    if kekulize:\n",
    "        Chem.Kekulize(mol)\n",
    "    if use_3d:\n",
    "        AllChem.EmbedMolecule(mol, randomSeed=42)  # Generate 3D structure\n",
    "        AllChem.MMFFOptimizeMolecule(mol)  # Optional: optimize geometry\n",
    "\n",
    "    data = from_rdmol(mol, use_3d=use_3d)\n",
    "    data.smiles = smiles\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_rdmol(\n",
    "    data: 'torch_geometric.data.Data',\n",
    "    kekulize: bool = False,\n",
    ") -> Any:\n",
    "    \"\"\"Converts a :class:`torch_geometric.data.Data` instance to a\n",
    "    :class:`rdkit.Chem.Mol` instance.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The molecular graph data.\n",
    "        kekulize (bool, optional): If set to :obj:`True`, converts aromatic\n",
    "            bonds to single/double bonds. (default: :obj:`False`)\n",
    "    \"\"\"\n",
    "    from rdkit import Chem\n",
    "\n",
    "    mol = Chem.RWMol()\n",
    "\n",
    "    assert data.x is not None\n",
    "    assert data.num_nodes is not None\n",
    "    assert data.edge_index is not None\n",
    "    assert data.edge_attr is not None\n",
    "    for i in range(data.num_nodes):\n",
    "        atom = Chem.Atom(int(data.x[i, 0]))\n",
    "        atom.SetChiralTag(Chem.rdchem.ChiralType.values[int(data.x[i, 1])])\n",
    "        atom.SetFormalCharge(x_map['formal_charge'][int(data.x[i, 3])])\n",
    "        atom.SetNumExplicitHs(x_map['num_hs'][int(data.x[i, 4])])\n",
    "        atom.SetNumRadicalElectrons(x_map['num_radical_electrons'][int(\n",
    "            data.x[i, 5])])\n",
    "        atom.SetHybridization(Chem.rdchem.HybridizationType.values[int(\n",
    "            data.x[i, 6])])\n",
    "        atom.SetIsAromatic(bool(data.x[i, 7]))\n",
    "        mol.AddAtom(atom)\n",
    "\n",
    "    edges = [tuple(i) for i in data.edge_index.t().tolist()]\n",
    "    visited = set()\n",
    "\n",
    "    for i in range(len(edges)):\n",
    "        src, dst = edges[i]\n",
    "        if tuple(sorted(edges[i])) in visited:\n",
    "            continue\n",
    "\n",
    "        bond_type = Chem.BondType.values[int(data.edge_attr[i, 0])]\n",
    "        mol.AddBond(src, dst, bond_type)\n",
    "\n",
    "        # Set stereochemistry:\n",
    "        stereo = Chem.rdchem.BondStereo.values[int(data.edge_attr[i, 1])]\n",
    "        if stereo != Chem.rdchem.BondStereo.STEREONONE:\n",
    "            db = mol.GetBondBetweenAtoms(src, dst)\n",
    "            db.SetStereoAtoms(dst, src)\n",
    "            db.SetStereo(stereo)\n",
    "\n",
    "        # Set conjugation:\n",
    "        is_conjugated = bool(data.edge_attr[i, 2])\n",
    "        mol.GetBondBetweenAtoms(src, dst).SetIsConjugated(is_conjugated)\n",
    "\n",
    "        visited.add(tuple(sorted(edges[i])))\n",
    "\n",
    "    mol = mol.GetMol()\n",
    "\n",
    "    if kekulize:\n",
    "        Chem.Kekulize(mol)\n",
    "\n",
    "    Chem.SanitizeMol(mol)\n",
    "    Chem.AssignStereochemistry(mol)\n",
    "\n",
    "    return mol\n",
    "\n",
    "\n",
    "def to_smiles(\n",
    "    data: 'torch_geometric.data.Data',\n",
    "    kekulize: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Converts a :class:`torch_geometric.data.Data` instance to a SMILES\n",
    "    string.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The molecular graph.\n",
    "        kekulize (bool, optional): If set to :obj:`True`, converts aromatic\n",
    "            bonds to single/double bonds. (default: :obj:`False`)\n",
    "    \"\"\"\n",
    "    from rdkit import Chem\n",
    "    mol = to_rdmol(data, kekulize=kekulize)\n",
    "    return Chem.MolToSmiles(mol, isomericSmiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "18305704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                smiles    gap\n",
      "0    COC(=O)/C(=C/c1cc(C)c(c2ccc(c3sc(c4cc5c(s4)c(O...  0.235\n",
      "1                  Cc1csc(c2ccc(c3cc(C)cs3)c3nsnc23)c1  0.262\n",
      "2    COC(=O)/C(=C/c1cc(C)c(c2cc(C)c(c3ccc(c4sc(c5sc...  0.234\n",
      "3    C[Si]1(C)c2ccsc2c2sc(c3nc4sc(c5cc6c(s5)c5sc(c7...  0.245\n",
      "4    COc1c2ccsc2c(OC)c2cc(c3sc(c4scc5c4[C@@H]4C=C[C...  0.300\n",
      "..                                                 ...    ...\n",
      "311  Cc1c2ccsc2c(C)c2cc(c3ccc(c4cnc(c5cccs5)c5nsnc4...  0.236\n",
      "312       CC(=O)c1cc2c(csc2c2cc3c(s2)c(C)c2ccsc2c3C)s1  0.276\n",
      "313  Cc1cc(c2ccc(N(c3ccccc3)c3ccccc3)cc2)sc1c1cnc(c...  0.258\n",
      "314  Cc1ccc(C2(c3ccc(C)cc3)c3ccsc3c3cc4c(cc23)c2sc(...  0.255\n",
      "315  Cc1cc(c2cc3c4nsnc4c(c4cc(C)c(c5cccs5)s4)cc3c3n...  0.231\n",
      "\n",
      "[316 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('mat_bandgap_morgan.pkl')\n",
    "df = df.drop(['Morgan','confnum','homo','lumo'],axis=1)\n",
    "mols = [Chem.MolFromSmiles(x) for x in df['smiles']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70f8f316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1csc(c2ccsc2c2cccs2)c1\n"
     ]
    }
   ],
   "source": [
    "# example for one molecule:\n",
    "\n",
    "smile = df['smiles'][35]\n",
    "print(smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3232641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[23, 16], edge_index=[2, 50], edge_attr=[50, 3], pos=[23, 3], smiles='c1csc(c2ccsc2c2cccs2)c1')\n"
     ]
    }
   ],
   "source": [
    "# this generates a torch Data object for the molecule\n",
    "\n",
    "g = from_smiles(smile, with_hydrogen=True, kekulize=True, use_3d=True)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1041783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [16,  0,  2,  5,  0,  0,  3,  1,  1,  1,  2,  0,  2, 32,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [16,  0,  2,  5,  0,  0,  3,  1,  1,  1,  2,  0,  2, 32,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [16,  0,  2,  5,  0,  0,  3,  1,  1,  1,  2,  0,  2, 32,  0,  5],\n",
       "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1,  1,  4,  0,  4, 12,  0,  5],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "        [ 1,  0,  1,  5,  0,  0,  0,  0,  0,  0,  1,  0,  1,  1,  0,  0]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this prints the node feature matrix - so all the atoms in the molecule and some metrics for them\n",
    "g.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2633753d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this prints the number of nodes:\n",
    "\n",
    "g.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96067ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9938d203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  1,  1,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,  6,\n",
       "          6,  6,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12,\n",
       "         12, 13, 13, 14, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
       "        [ 1, 14, 15,  0,  2, 16,  1,  3,  2,  4, 14,  3,  5,  8,  4,  6, 17,  5,\n",
       "          7, 18,  6,  8,  4,  7,  9,  8, 10, 13,  9, 11, 19, 10, 12, 20, 11, 13,\n",
       "         21,  9, 12,  0,  3, 22,  0,  1,  5,  6, 10, 11, 12, 14]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b960cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  1],\n",
       "        [ 1,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [12,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c727116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates data objects for all the molecules in the dataset\n",
    "\n",
    "graph_list = []\n",
    "\n",
    "for i, smile in enumerate(df['smiles']):\n",
    "    g = from_smiles(smile)\n",
    "    g.x = g.x.float()\n",
    "    y = torch.tensor(df['gap'][i],dtype=torch.float).view(1,-1)\n",
    "    g.y = y\n",
    "    graph_list.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1777eb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.data.Data"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7cba0b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[21, 16], edge_index=[2, 48], edge_attr=[48, 3], smiles='Cc1csc(c2ccc(c3cc(C)cs3)c3nsnc23)c1', y=[1, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ee9cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "train_ratio = 0.80\n",
    "dataset_size = len(graph_list)\n",
    "train_size = int(train_ratio*dataset_size)\n",
    "test_size = dataset_size-train_size\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_dataset, test_dataset = random_split(graph_list,[train_size,test_size], generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aa95261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed3800ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60417293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[66, 16], edge_index=[2, 148], edge_attr=[148, 3], smiles='COC(=O)/C(=C/c1cc(C)c(c2ccc(c3sc(c4cc5c(s4)c(OC)c4cc(c6cc(C)c(c7ccc(c8sc(/C=C(\\C#N)/C(=O)OC)cc8C)s7)s6)sc4c5OC)cc3C)s2)s1)/C#N', y=[1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8c8df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveFP(in_channels=16,hidden_channels=64,out_channels=1,edge_dim=3,num_layers=3,num_timesteps=2,dropout=0.2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=10**-5)\n",
    "\n",
    "loss_function = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5722fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentiveFP(in_channels=11, hidden_channels=64, out_channels=1, edge_dim=3, num_layers=2, num_timesteps=2)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f11c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss: 2.2767 Train R²: -3289.6155 Test Loss: 0.1839 Test R²: -293.0222\n",
      "1 Train Loss: 0.2227 Train R²: -319.8301 Test Loss: 0.0094 Test R²: -14.0415\n",
      "2 Train Loss: 0.0714 Train R²: -101.1672 Test Loss: 0.0399 Test R²: -62.7964\n",
      "3 Train Loss: 0.0364 Train R²: -51.2871 Test Loss: 0.0126 Test R²: -19.1459\n",
      "4 Train Loss: 0.0297 Train R²: -41.4124 Test Loss: 0.0044 Test R²: -6.0579\n",
      "5 Train Loss: 0.0239 Train R²: -32.8167 Test Loss: 0.0021 Test R²: -2.4265\n",
      "6 Train Loss: 0.0163 Train R²: -22.2307 Test Loss: 0.0003 Test R²: 0.4441\n",
      "7 Train Loss: 0.0139 Train R²: -18.6989 Test Loss: 0.0005 Test R²: 0.1459\n",
      "8 Train Loss: 0.0154 Train R²: -20.9659 Test Loss: 0.0018 Test R²: -1.9295\n",
      "9 Train Loss: 0.0094 Train R²: -12.3252 Test Loss: 0.0011 Test R²: -0.7659\n",
      "10 Train Loss: 0.0097 Train R²: -12.8862 Test Loss: 0.0006 Test R²: 0.0249\n",
      "11 Train Loss: 0.0102 Train R²: -13.4427 Test Loss: 0.0007 Test R²: -0.1511\n",
      "12 Train Loss: 0.0079 Train R²: -10.2754 Test Loss: 0.0007 Test R²: -0.0983\n",
      "13 Train Loss: 0.0069 Train R²: -8.8670 Test Loss: 0.0006 Test R²: 0.0887\n",
      "14 Train Loss: 0.0061 Train R²: -7.7054 Test Loss: 0.0005 Test R²: 0.1383\n",
      "15 Train Loss: 0.0065 Train R²: -8.3214 Test Loss: 0.0006 Test R²: 0.0296\n",
      "16 Train Loss: 0.0057 Train R²: -7.2267 Test Loss: 0.0006 Test R²: 0.0669\n",
      "17 Train Loss: 0.0045 Train R²: -5.4923 Test Loss: 0.0006 Test R²: 0.0202\n",
      "18 Train Loss: 0.0040 Train R²: -4.7192 Test Loss: 0.0004 Test R²: 0.3421\n",
      "19 Train Loss: 0.0031 Train R²: -3.3847 Test Loss: 0.0004 Test R²: 0.3828\n",
      "20 Train Loss: 0.0038 Train R²: -4.3842 Test Loss: 0.0005 Test R²: 0.1501\n",
      "21 Train Loss: 0.0025 Train R²: -2.5249 Test Loss: 0.0003 Test R²: 0.4483\n",
      "22 Train Loss: 0.0025 Train R²: -2.5563 Test Loss: 0.0005 Test R²: 0.2761\n",
      "23 Train Loss: 0.0027 Train R²: -2.8396 Test Loss: 0.0004 Test R²: 0.4177\n",
      "24 Train Loss: 0.0024 Train R²: -2.3708 Test Loss: 0.0003 Test R²: 0.4453\n",
      "25 Train Loss: 0.0020 Train R²: -1.7866 Test Loss: 0.0004 Test R²: 0.3596\n",
      "26 Train Loss: 0.0017 Train R²: -1.4830 Test Loss: 0.0004 Test R²: 0.3870\n",
      "27 Train Loss: 0.0021 Train R²: -2.0166 Test Loss: 0.0004 Test R²: 0.3905\n",
      "28 Train Loss: 0.0016 Train R²: -1.3199 Test Loss: 0.0005 Test R²: 0.1365\n",
      "29 Train Loss: 0.0015 Train R²: -1.1159 Test Loss: 0.0005 Test R²: 0.2751\n",
      "30 Train Loss: 0.0018 Train R²: -1.6359 Test Loss: 0.0004 Test R²: 0.4239\n",
      "31 Train Loss: 0.0014 Train R²: -0.9968 Test Loss: 0.0003 Test R²: 0.5128\n",
      "32 Train Loss: 0.0015 Train R²: -1.0979 Test Loss: 0.0005 Test R²: 0.1902\n",
      "33 Train Loss: 0.0014 Train R²: -1.0624 Test Loss: 0.0005 Test R²: 0.1695\n",
      "34 Train Loss: 0.0014 Train R²: -1.0497 Test Loss: 0.0004 Test R²: 0.2895\n",
      "35 Train Loss: 0.0015 Train R²: -1.0784 Test Loss: 0.0003 Test R²: 0.4832\n",
      "36 Train Loss: 0.0017 Train R²: -1.4349 Test Loss: 0.0005 Test R²: 0.1348\n",
      "37 Train Loss: 0.0013 Train R²: -0.8946 Test Loss: 0.0006 Test R²: 0.0383\n",
      "38 Train Loss: 0.0013 Train R²: -0.8845 Test Loss: 0.0004 Test R²: 0.3656\n",
      "39 Train Loss: 0.0013 Train R²: -0.9251 Test Loss: 0.0004 Test R²: 0.3154\n",
      "40 Train Loss: 0.0013 Train R²: -0.9071 Test Loss: 0.0004 Test R²: 0.3446\n",
      "41 Train Loss: 0.0011 Train R²: -0.6417 Test Loss: 0.0004 Test R²: 0.4122\n",
      "42 Train Loss: 0.0012 Train R²: -0.7611 Test Loss: 0.0004 Test R²: 0.3729\n",
      "43 Train Loss: 0.0014 Train R²: -0.9321 Test Loss: 0.0005 Test R²: 0.1940\n",
      "44 Train Loss: 0.0013 Train R²: -0.8946 Test Loss: 0.0003 Test R²: 0.4568\n",
      "45 Train Loss: 0.0013 Train R²: -0.8992 Test Loss: 0.0006 Test R²: 0.0994\n",
      "46 Train Loss: 0.0013 Train R²: -0.8445 Test Loss: 0.0003 Test R²: 0.4750\n",
      "47 Train Loss: 0.0013 Train R²: -0.8153 Test Loss: 0.0005 Test R²: 0.2101\n",
      "48 Train Loss: 0.0012 Train R²: -0.7378 Test Loss: 0.0005 Test R²: 0.1848\n",
      "49 Train Loss: 0.0012 Train R²: -0.7317 Test Loss: 0.0005 Test R²: 0.2739\n",
      "50 Train Loss: 0.0011 Train R²: -0.5231 Test Loss: 0.0004 Test R²: 0.3012\n",
      "51 Train Loss: 0.0011 Train R²: -0.6343 Test Loss: 0.0003 Test R²: 0.4421\n",
      "52 Train Loss: 0.0011 Train R²: -0.6011 Test Loss: 0.0005 Test R²: 0.2752\n",
      "53 Train Loss: 0.0012 Train R²: -0.7207 Test Loss: 0.0004 Test R²: 0.4045\n",
      "54 Train Loss: 0.0011 Train R²: -0.6058 Test Loss: 0.0003 Test R²: 0.4624\n",
      "55 Train Loss: 0.0010 Train R²: -0.4090 Test Loss: 0.0004 Test R²: 0.3418\n",
      "56 Train Loss: 0.0010 Train R²: -0.4054 Test Loss: 0.0004 Test R²: 0.4398\n",
      "57 Train Loss: 0.0009 Train R²: -0.2388 Test Loss: 0.0003 Test R²: 0.5144\n",
      "58 Train Loss: 0.0010 Train R²: -0.3640 Test Loss: 0.0004 Test R²: 0.3047\n",
      "59 Train Loss: 0.0010 Train R²: -0.4522 Test Loss: 0.0004 Test R²: 0.4345\n",
      "60 Train Loss: 0.0010 Train R²: -0.4584 Test Loss: 0.0003 Test R²: 0.4473\n",
      "61 Train Loss: 0.0009 Train R²: -0.2895 Test Loss: 0.0003 Test R²: 0.4458\n",
      "62 Train Loss: 0.0011 Train R²: -0.5388 Test Loss: 0.0003 Test R²: 0.4684\n",
      "63 Train Loss: 0.0010 Train R²: -0.4637 Test Loss: 0.0004 Test R²: 0.4097\n",
      "64 Train Loss: 0.0012 Train R²: -0.6467 Test Loss: 0.0003 Test R²: 0.4952\n",
      "65 Train Loss: 0.0009 Train R²: -0.3191 Test Loss: 0.0003 Test R²: 0.4458\n",
      "66 Train Loss: 0.0009 Train R²: -0.3320 Test Loss: 0.0003 Test R²: 0.4722\n",
      "67 Train Loss: 0.0011 Train R²: -0.5287 Test Loss: 0.0003 Test R²: 0.4411\n",
      "68 Train Loss: 0.0010 Train R²: -0.4739 Test Loss: 0.0005 Test R²: 0.1756\n",
      "69 Train Loss: 0.0011 Train R²: -0.5080 Test Loss: 0.0004 Test R²: 0.3605\n",
      "70 Train Loss: 0.0009 Train R²: -0.3615 Test Loss: 0.0003 Test R²: 0.4528\n",
      "71 Train Loss: 0.0010 Train R²: -0.4874 Test Loss: 0.0003 Test R²: 0.4589\n",
      "72 Train Loss: 0.0009 Train R²: -0.3542 Test Loss: 0.0003 Test R²: 0.4857\n",
      "73 Train Loss: 0.0010 Train R²: -0.3784 Test Loss: 0.0003 Test R²: 0.5038\n",
      "74 Train Loss: 0.0009 Train R²: -0.2658 Test Loss: 0.0003 Test R²: 0.5407\n",
      "75 Train Loss: 0.0011 Train R²: -0.6415 Test Loss: 0.0003 Test R²: 0.5151\n",
      "76 Train Loss: 0.0009 Train R²: -0.3553 Test Loss: 0.0003 Test R²: 0.5184\n",
      "77 Train Loss: 0.0009 Train R²: -0.2293 Test Loss: 0.0003 Test R²: 0.5195\n",
      "78 Train Loss: 0.0010 Train R²: -0.3994 Test Loss: 0.0003 Test R²: 0.4826\n",
      "79 Train Loss: 0.0010 Train R²: -0.4234 Test Loss: 0.0003 Test R²: 0.5464\n",
      "80 Train Loss: 0.0008 Train R²: -0.0828 Test Loss: 0.0003 Test R²: 0.5376\n",
      "81 Train Loss: 0.0010 Train R²: -0.4592 Test Loss: 0.0003 Test R²: 0.5329\n",
      "82 Train Loss: 0.0010 Train R²: -0.4588 Test Loss: 0.0003 Test R²: 0.5479\n",
      "83 Train Loss: 0.0010 Train R²: -0.3694 Test Loss: 0.0003 Test R²: 0.5460\n",
      "84 Train Loss: 0.0010 Train R²: -0.4211 Test Loss: 0.0003 Test R²: 0.5527\n",
      "85 Train Loss: 0.0010 Train R²: -0.3901 Test Loss: 0.0003 Test R²: 0.5560\n",
      "86 Train Loss: 0.0009 Train R²: -0.2985 Test Loss: 0.0003 Test R²: 0.5469\n",
      "87 Train Loss: 0.0008 Train R²: -0.2065 Test Loss: 0.0003 Test R²: 0.5474\n",
      "88 Train Loss: 0.0008 Train R²: -0.1474 Test Loss: 0.0003 Test R²: 0.4635\n",
      "89 Train Loss: 0.0009 Train R²: -0.2371 Test Loss: 0.0003 Test R²: 0.5380\n",
      "90 Train Loss: 0.0008 Train R²: -0.1571 Test Loss: 0.0003 Test R²: 0.5373\n",
      "91 Train Loss: 0.0009 Train R²: -0.2543 Test Loss: 0.0003 Test R²: 0.5314\n",
      "92 Train Loss: 0.0010 Train R²: -0.3772 Test Loss: 0.0003 Test R²: 0.5412\n",
      "93 Train Loss: 0.0008 Train R²: -0.1371 Test Loss: 0.0003 Test R²: 0.5500\n",
      "94 Train Loss: 0.0011 Train R²: -0.6092 Test Loss: 0.0003 Test R²: 0.5359\n",
      "95 Train Loss: 0.0008 Train R²: -0.1457 Test Loss: 0.0003 Test R²: 0.4884\n",
      "96 Train Loss: 0.0009 Train R²: -0.2446 Test Loss: 0.0003 Test R²: 0.5488\n",
      "97 Train Loss: 0.0008 Train R²: -0.1366 Test Loss: 0.0004 Test R²: 0.4067\n",
      "98 Train Loss: 0.0008 Train R²: -0.1424 Test Loss: 0.0003 Test R²: 0.4863\n",
      "99 Train Loss: 0.0010 Train R²: -0.3594 Test Loss: 0.0003 Test R²: 0.5464\n",
      "100 Train Loss: 0.0008 Train R²: -0.1199 Test Loss: 0.0003 Test R²: 0.5206\n",
      "101 Train Loss: 0.0009 Train R²: -0.2658 Test Loss: 0.0003 Test R²: 0.5246\n",
      "102 Train Loss: 0.0009 Train R²: -0.3520 Test Loss: 0.0003 Test R²: 0.5620\n",
      "103 Train Loss: 0.0010 Train R²: -0.4075 Test Loss: 0.0003 Test R²: 0.5531\n",
      "104 Train Loss: 0.0009 Train R²: -0.2496 Test Loss: 0.0003 Test R²: 0.5448\n",
      "105 Train Loss: 0.0008 Train R²: -0.0835 Test Loss: 0.0003 Test R²: 0.5047\n",
      "106 Train Loss: 0.0009 Train R²: -0.3107 Test Loss: 0.0003 Test R²: 0.5209\n",
      "107 Train Loss: 0.0010 Train R²: -0.3894 Test Loss: 0.0003 Test R²: 0.5382\n",
      "108 Train Loss: 0.0007 Train R²: -0.0670 Test Loss: 0.0003 Test R²: 0.4832\n",
      "109 Train Loss: 0.0008 Train R²: -0.0946 Test Loss: 0.0003 Test R²: 0.5258\n",
      "110 Train Loss: 0.0008 Train R²: -0.1433 Test Loss: 0.0003 Test R²: 0.5467\n",
      "111 Train Loss: 0.0007 Train R²: 0.0059 Test Loss: 0.0004 Test R²: 0.3058\n",
      "112 Train Loss: 0.0009 Train R²: -0.3447 Test Loss: 0.0003 Test R²: 0.5306\n",
      "113 Train Loss: 0.0009 Train R²: -0.2164 Test Loss: 0.0003 Test R²: 0.4885\n",
      "114 Train Loss: 0.0009 Train R²: -0.2496 Test Loss: 0.0004 Test R²: 0.4256\n",
      "115 Train Loss: 0.0008 Train R²: -0.0937 Test Loss: 0.0003 Test R²: 0.5173\n",
      "116 Train Loss: 0.0008 Train R²: -0.1702 Test Loss: 0.0004 Test R²: 0.4335\n",
      "117 Train Loss: 0.0008 Train R²: -0.2137 Test Loss: 0.0003 Test R²: 0.5427\n",
      "118 Train Loss: 0.0009 Train R²: -0.2805 Test Loss: 0.0003 Test R²: 0.4974\n",
      "119 Train Loss: 0.0009 Train R²: -0.3206 Test Loss: 0.0003 Test R²: 0.5217\n",
      "120 Train Loss: 0.0008 Train R²: -0.0985 Test Loss: 0.0003 Test R²: 0.5596\n",
      "121 Train Loss: 0.0008 Train R²: -0.1712 Test Loss: 0.0003 Test R²: 0.4405\n",
      "122 Train Loss: 0.0009 Train R²: -0.2846 Test Loss: 0.0003 Test R²: 0.5598\n",
      "123 Train Loss: 0.0008 Train R²: -0.0967 Test Loss: 0.0003 Test R²: 0.5329\n",
      "124 Train Loss: 0.0008 Train R²: -0.1132 Test Loss: 0.0003 Test R²: 0.5417\n",
      "125 Train Loss: 0.0009 Train R²: -0.2695 Test Loss: 0.0003 Test R²: 0.5613\n",
      "126 Train Loss: 0.0008 Train R²: -0.1135 Test Loss: 0.0003 Test R²: 0.5464\n",
      "127 Train Loss: 0.0008 Train R²: -0.1589 Test Loss: 0.0003 Test R²: 0.5300\n",
      "128 Train Loss: 0.0008 Train R²: -0.1734 Test Loss: 0.0003 Test R²: 0.5582\n",
      "129 Train Loss: 0.0008 Train R²: -0.1752 Test Loss: 0.0003 Test R²: 0.5645\n",
      "130 Train Loss: 0.0009 Train R²: -0.2206 Test Loss: 0.0003 Test R²: 0.5572\n",
      "131 Train Loss: 0.0007 Train R²: -0.0565 Test Loss: 0.0003 Test R²: 0.5692\n",
      "132 Train Loss: 0.0008 Train R²: -0.1413 Test Loss: 0.0003 Test R²: 0.5626\n",
      "133 Train Loss: 0.0008 Train R²: -0.1019 Test Loss: 0.0003 Test R²: 0.5070\n",
      "134 Train Loss: 0.0007 Train R²: -0.0699 Test Loss: 0.0003 Test R²: 0.5638\n",
      "135 Train Loss: 0.0007 Train R²: 0.0429 Test Loss: 0.0003 Test R²: 0.5004\n",
      "136 Train Loss: 0.0009 Train R²: -0.2999 Test Loss: 0.0003 Test R²: 0.5530\n",
      "137 Train Loss: 0.0009 Train R²: -0.2152 Test Loss: 0.0003 Test R²: 0.5507\n",
      "138 Train Loss: 0.0008 Train R²: -0.1595 Test Loss: 0.0003 Test R²: 0.4547\n",
      "139 Train Loss: 0.0008 Train R²: -0.2175 Test Loss: 0.0003 Test R²: 0.5552\n",
      "140 Train Loss: 0.0008 Train R²: -0.1022 Test Loss: 0.0003 Test R²: 0.5674\n",
      "141 Train Loss: 0.0008 Train R²: -0.2024 Test Loss: 0.0003 Test R²: 0.5533\n",
      "142 Train Loss: 0.0007 Train R²: 0.0468 Test Loss: 0.0003 Test R²: 0.5645\n",
      "143 Train Loss: 0.0009 Train R²: -0.2353 Test Loss: 0.0003 Test R²: 0.5280\n",
      "144 Train Loss: 0.0007 Train R²: 0.0306 Test Loss: 0.0003 Test R²: 0.5485\n",
      "145 Train Loss: 0.0008 Train R²: -0.1322 Test Loss: 0.0003 Test R²: 0.5030\n",
      "146 Train Loss: 0.0007 Train R²: -0.0251 Test Loss: 0.0003 Test R²: 0.4939\n",
      "147 Train Loss: 0.0008 Train R²: -0.1097 Test Loss: 0.0003 Test R²: 0.5063\n",
      "148 Train Loss: 0.0007 Train R²: -0.0140 Test Loss: 0.0003 Test R²: 0.4892\n",
      "149 Train Loss: 0.0008 Train R²: -0.1338 Test Loss: 0.0003 Test R²: 0.5299\n",
      "150 Train Loss: 0.0007 Train R²: -0.0536 Test Loss: 0.0003 Test R²: 0.5428\n",
      "151 Train Loss: 0.0007 Train R²: 0.0083 Test Loss: 0.0003 Test R²: 0.5079\n",
      "152 Train Loss: 0.0008 Train R²: -0.0992 Test Loss: 0.0003 Test R²: 0.5424\n",
      "153 Train Loss: 0.0007 Train R²: 0.0455 Test Loss: 0.0005 Test R²: 0.1386\n",
      "154 Train Loss: 0.0008 Train R²: -0.0733 Test Loss: 0.0003 Test R²: 0.5542\n",
      "155 Train Loss: 0.0007 Train R²: 0.0069 Test Loss: 0.0003 Test R²: 0.5560\n",
      "156 Train Loss: 0.0008 Train R²: -0.0989 Test Loss: 0.0003 Test R²: 0.5676\n",
      "157 Train Loss: 0.0009 Train R²: -0.2366 Test Loss: 0.0003 Test R²: 0.5741\n",
      "158 Train Loss: 0.0008 Train R²: -0.1054 Test Loss: 0.0003 Test R²: 0.5503\n",
      "159 Train Loss: 0.0007 Train R²: -0.0274 Test Loss: 0.0003 Test R²: 0.5259\n",
      "160 Train Loss: 0.0008 Train R²: -0.1477 Test Loss: 0.0003 Test R²: 0.5237\n",
      "161 Train Loss: 0.0008 Train R²: -0.0877 Test Loss: 0.0003 Test R²: 0.5206\n",
      "162 Train Loss: 0.0006 Train R²: 0.1544 Test Loss: 0.0003 Test R²: 0.4587\n",
      "163 Train Loss: 0.0006 Train R²: 0.1858 Test Loss: 0.0003 Test R²: 0.5331\n",
      "164 Train Loss: 0.0007 Train R²: -0.0265 Test Loss: 0.0003 Test R²: 0.4613\n",
      "165 Train Loss: 0.0008 Train R²: -0.1414 Test Loss: 0.0003 Test R²: 0.5667\n",
      "166 Train Loss: 0.0008 Train R²: -0.0972 Test Loss: 0.0003 Test R²: 0.5529\n",
      "167 Train Loss: 0.0007 Train R²: 0.0408 Test Loss: 0.0003 Test R²: 0.5294\n",
      "168 Train Loss: 0.0008 Train R²: -0.1123 Test Loss: 0.0003 Test R²: 0.5740\n",
      "169 Train Loss: 0.0007 Train R²: 0.0141 Test Loss: 0.0003 Test R²: 0.5557\n",
      "170 Train Loss: 0.0007 Train R²: -0.0481 Test Loss: 0.0003 Test R²: 0.5621\n",
      "171 Train Loss: 0.0007 Train R²: 0.0528 Test Loss: 0.0003 Test R²: 0.5697\n",
      "172 Train Loss: 0.0007 Train R²: 0.0614 Test Loss: 0.0003 Test R²: 0.5538\n",
      "173 Train Loss: 0.0008 Train R²: -0.0823 Test Loss: 0.0003 Test R²: 0.5625\n",
      "174 Train Loss: 0.0008 Train R²: -0.0693 Test Loss: 0.0003 Test R²: 0.5705\n",
      "175 Train Loss: 0.0007 Train R²: 0.0460 Test Loss: 0.0003 Test R²: 0.5800\n",
      "176 Train Loss: 0.0007 Train R²: -0.0378 Test Loss: 0.0003 Test R²: 0.5772\n",
      "177 Train Loss: 0.0007 Train R²: -0.0186 Test Loss: 0.0003 Test R²: 0.5791\n",
      "178 Train Loss: 0.0008 Train R²: -0.1009 Test Loss: 0.0003 Test R²: 0.5284\n",
      "179 Train Loss: 0.0006 Train R²: 0.1045 Test Loss: 0.0003 Test R²: 0.5560\n",
      "180 Train Loss: 0.0008 Train R²: -0.1579 Test Loss: 0.0003 Test R²: 0.4947\n",
      "181 Train Loss: 0.0008 Train R²: -0.1063 Test Loss: 0.0003 Test R²: 0.5277\n",
      "182 Train Loss: 0.0006 Train R²: 0.0734 Test Loss: 0.0003 Test R²: 0.5396\n",
      "183 Train Loss: 0.0007 Train R²: 0.0277 Test Loss: 0.0003 Test R²: 0.5631\n",
      "184 Train Loss: 0.0007 Train R²: 0.0205 Test Loss: 0.0003 Test R²: 0.5416\n",
      "185 Train Loss: 0.0008 Train R²: -0.1845 Test Loss: 0.0003 Test R²: 0.5437\n",
      "186 Train Loss: 0.0006 Train R²: 0.0926 Test Loss: 0.0003 Test R²: 0.4683\n",
      "187 Train Loss: 0.0007 Train R²: 0.0387 Test Loss: 0.0003 Test R²: 0.5660\n",
      "188 Train Loss: 0.0006 Train R²: 0.1175 Test Loss: 0.0003 Test R²: 0.5702\n",
      "189 Train Loss: 0.0006 Train R²: 0.1045 Test Loss: 0.0003 Test R²: 0.5407\n",
      "190 Train Loss: 0.0007 Train R²: 0.0619 Test Loss: 0.0003 Test R²: 0.5856\n",
      "191 Train Loss: 0.0006 Train R²: 0.1498 Test Loss: 0.0003 Test R²: 0.5443\n",
      "192 Train Loss: 0.0006 Train R²: 0.1040 Test Loss: 0.0003 Test R²: 0.5630\n",
      "193 Train Loss: 0.0006 Train R²: 0.1040 Test Loss: 0.0003 Test R²: 0.5310\n",
      "194 Train Loss: 0.0006 Train R²: 0.1013 Test Loss: 0.0003 Test R²: 0.5856\n",
      "195 Train Loss: 0.0006 Train R²: 0.0994 Test Loss: 0.0003 Test R²: 0.5850\n",
      "196 Train Loss: 0.0006 Train R²: 0.0877 Test Loss: 0.0003 Test R²: 0.5865\n",
      "197 Train Loss: 0.0007 Train R²: -0.0358 Test Loss: 0.0003 Test R²: 0.5818\n",
      "198 Train Loss: 0.0006 Train R²: 0.0985 Test Loss: 0.0003 Test R²: 0.5460\n",
      "199 Train Loss: 0.0006 Train R²: 0.1729 Test Loss: 0.0003 Test R²: 0.5609\n",
      "200 Train Loss: 0.0007 Train R²: -0.0406 Test Loss: 0.0003 Test R²: 0.5547\n",
      "201 Train Loss: 0.0007 Train R²: 0.0369 Test Loss: 0.0003 Test R²: 0.5662\n",
      "202 Train Loss: 0.0006 Train R²: 0.0824 Test Loss: 0.0003 Test R²: 0.5629\n",
      "203 Train Loss: 0.0007 Train R²: 0.0162 Test Loss: 0.0003 Test R²: 0.5705\n",
      "204 Train Loss: 0.0007 Train R²: 0.0404 Test Loss: 0.0003 Test R²: 0.4887\n",
      "205 Train Loss: 0.0007 Train R²: 0.0445 Test Loss: 0.0003 Test R²: 0.5188\n",
      "206 Train Loss: 0.0007 Train R²: 0.0474 Test Loss: 0.0004 Test R²: 0.4263\n",
      "207 Train Loss: 0.0007 Train R²: -0.0164 Test Loss: 0.0003 Test R²: 0.4830\n",
      "208 Train Loss: 0.0006 Train R²: 0.1054 Test Loss: 0.0003 Test R²: 0.5198\n",
      "209 Train Loss: 0.0007 Train R²: -0.0070 Test Loss: 0.0003 Test R²: 0.5171\n",
      "210 Train Loss: 0.0006 Train R²: 0.0860 Test Loss: 0.0003 Test R²: 0.5560\n",
      "211 Train Loss: 0.0006 Train R²: 0.0793 Test Loss: 0.0003 Test R²: 0.5800\n",
      "212 Train Loss: 0.0007 Train R²: 0.0159 Test Loss: 0.0003 Test R²: 0.5910\n",
      "213 Train Loss: 0.0006 Train R²: 0.1737 Test Loss: 0.0003 Test R²: 0.5838\n",
      "214 Train Loss: 0.0006 Train R²: 0.1927 Test Loss: 0.0003 Test R²: 0.5177\n",
      "215 Train Loss: 0.0006 Train R²: 0.1175 Test Loss: 0.0003 Test R²: 0.5835\n",
      "216 Train Loss: 0.0005 Train R²: 0.3131 Test Loss: 0.0003 Test R²: 0.5792\n",
      "217 Train Loss: 0.0006 Train R²: 0.1279 Test Loss: 0.0003 Test R²: 0.5602\n",
      "218 Train Loss: 0.0006 Train R²: 0.1806 Test Loss: 0.0003 Test R²: 0.5850\n",
      "219 Train Loss: 0.0007 Train R²: 0.0615 Test Loss: 0.0003 Test R²: 0.5900\n",
      "220 Train Loss: 0.0007 Train R²: 0.0258 Test Loss: 0.0003 Test R²: 0.5875\n",
      "221 Train Loss: 0.0006 Train R²: 0.0899 Test Loss: 0.0003 Test R²: 0.5534\n",
      "222 Train Loss: 0.0007 Train R²: 0.0474 Test Loss: 0.0003 Test R²: 0.5762\n",
      "223 Train Loss: 0.0007 Train R²: 0.0299 Test Loss: 0.0003 Test R²: 0.5756\n",
      "224 Train Loss: 0.0006 Train R²: 0.0964 Test Loss: 0.0003 Test R²: 0.5583\n",
      "225 Train Loss: 0.0007 Train R²: -0.0587 Test Loss: 0.0003 Test R²: 0.5573\n",
      "226 Train Loss: 0.0006 Train R²: 0.1530 Test Loss: 0.0003 Test R²: 0.5003\n",
      "227 Train Loss: 0.0006 Train R²: 0.1569 Test Loss: 0.0003 Test R²: 0.5597\n",
      "228 Train Loss: 0.0006 Train R²: 0.2012 Test Loss: 0.0003 Test R²: 0.4431\n",
      "229 Train Loss: 0.0006 Train R²: 0.0835 Test Loss: 0.0003 Test R²: 0.5461\n",
      "230 Train Loss: 0.0007 Train R²: -0.0340 Test Loss: 0.0003 Test R²: 0.4903\n",
      "231 Train Loss: 0.0005 Train R²: 0.2601 Test Loss: 0.0003 Test R²: 0.5517\n",
      "232 Train Loss: 0.0006 Train R²: 0.1017 Test Loss: 0.0003 Test R²: 0.5406\n",
      "233 Train Loss: 0.0007 Train R²: 0.0201 Test Loss: 0.0003 Test R²: 0.5789\n",
      "234 Train Loss: 0.0006 Train R²: 0.1003 Test Loss: 0.0003 Test R²: 0.5529\n",
      "235 Train Loss: 0.0006 Train R²: 0.1968 Test Loss: 0.0003 Test R²: 0.5783\n",
      "236 Train Loss: 0.0006 Train R²: 0.1850 Test Loss: 0.0003 Test R²: 0.5883\n",
      "237 Train Loss: 0.0006 Train R²: 0.1684 Test Loss: 0.0003 Test R²: 0.5838\n",
      "238 Train Loss: 0.0006 Train R²: 0.1840 Test Loss: 0.0003 Test R²: 0.5807\n",
      "239 Train Loss: 0.0007 Train R²: -0.0041 Test Loss: 0.0003 Test R²: 0.4870\n",
      "240 Train Loss: 0.0007 Train R²: 0.0311 Test Loss: 0.0003 Test R²: 0.5901\n",
      "241 Train Loss: 0.0007 Train R²: 0.0717 Test Loss: 0.0003 Test R²: 0.5883\n",
      "242 Train Loss: 0.0006 Train R²: 0.1086 Test Loss: 0.0003 Test R²: 0.5491\n",
      "243 Train Loss: 0.0006 Train R²: 0.1480 Test Loss: 0.0003 Test R²: 0.5927\n",
      "244 Train Loss: 0.0006 Train R²: 0.0867 Test Loss: 0.0003 Test R²: 0.5881\n",
      "245 Train Loss: 0.0006 Train R²: 0.1731 Test Loss: 0.0003 Test R²: 0.5915\n",
      "246 Train Loss: 0.0005 Train R²: 0.2348 Test Loss: 0.0003 Test R²: 0.5947\n",
      "247 Train Loss: 0.0006 Train R²: 0.1577 Test Loss: 0.0002 Test R²: 0.6030\n",
      "248 Train Loss: 0.0006 Train R²: 0.1583 Test Loss: 0.0002 Test R²: 0.6019\n",
      "249 Train Loss: 0.0005 Train R²: 0.2209 Test Loss: 0.0003 Test R²: 0.5984\n",
      "250 Train Loss: 0.0005 Train R²: 0.2236 Test Loss: 0.0003 Test R²: 0.5561\n",
      "251 Train Loss: 0.0005 Train R²: 0.2624 Test Loss: 0.0003 Test R²: 0.5930\n",
      "252 Train Loss: 0.0007 Train R²: 0.0581 Test Loss: 0.0003 Test R²: 0.5861\n",
      "253 Train Loss: 0.0006 Train R²: 0.1434 Test Loss: 0.0003 Test R²: 0.5883\n",
      "254 Train Loss: 0.0005 Train R²: 0.2189 Test Loss: 0.0003 Test R²: 0.5655\n",
      "255 Train Loss: 0.0006 Train R²: 0.1396 Test Loss: 0.0003 Test R²: 0.5711\n",
      "256 Train Loss: 0.0005 Train R²: 0.2565 Test Loss: 0.0003 Test R²: 0.5283\n",
      "257 Train Loss: 0.0006 Train R²: 0.1080 Test Loss: 0.0003 Test R²: 0.5894\n",
      "258 Train Loss: 0.0005 Train R²: 0.2525 Test Loss: 0.0003 Test R²: 0.5761\n",
      "259 Train Loss: 0.0006 Train R²: 0.1224 Test Loss: 0.0003 Test R²: 0.5868\n",
      "260 Train Loss: 0.0006 Train R²: 0.1623 Test Loss: 0.0003 Test R²: 0.5837\n",
      "261 Train Loss: 0.0007 Train R²: 0.0302 Test Loss: 0.0003 Test R²: 0.5883\n",
      "262 Train Loss: 0.0006 Train R²: 0.1317 Test Loss: 0.0003 Test R²: 0.5948\n",
      "263 Train Loss: 0.0006 Train R²: 0.2116 Test Loss: 0.0003 Test R²: 0.5848\n",
      "264 Train Loss: 0.0005 Train R²: 0.2581 Test Loss: 0.0003 Test R²: 0.5537\n",
      "265 Train Loss: 0.0005 Train R²: 0.2328 Test Loss: 0.0003 Test R²: 0.5412\n",
      "266 Train Loss: 0.0006 Train R²: 0.2063 Test Loss: 0.0003 Test R²: 0.5726\n",
      "267 Train Loss: 0.0006 Train R²: 0.1330 Test Loss: 0.0003 Test R²: 0.5108\n",
      "268 Train Loss: 0.0006 Train R²: 0.1486 Test Loss: 0.0003 Test R²: 0.5761\n",
      "269 Train Loss: 0.0005 Train R²: 0.3103 Test Loss: 0.0003 Test R²: 0.5894\n",
      "270 Train Loss: 0.0006 Train R²: 0.1492 Test Loss: 0.0003 Test R²: 0.5938\n",
      "271 Train Loss: 0.0005 Train R²: 0.2668 Test Loss: 0.0003 Test R²: 0.5772\n",
      "272 Train Loss: 0.0007 Train R²: -0.0557 Test Loss: 0.0003 Test R²: 0.5444\n",
      "273 Train Loss: 0.0006 Train R²: 0.1791 Test Loss: 0.0003 Test R²: 0.5637\n",
      "274 Train Loss: 0.0006 Train R²: 0.1221 Test Loss: 0.0003 Test R²: 0.4908\n",
      "275 Train Loss: 0.0005 Train R²: 0.2476 Test Loss: 0.0003 Test R²: 0.5661\n",
      "276 Train Loss: 0.0005 Train R²: 0.2568 Test Loss: 0.0003 Test R²: 0.5721\n",
      "277 Train Loss: 0.0005 Train R²: 0.2692 Test Loss: 0.0003 Test R²: 0.5830\n",
      "278 Train Loss: 0.0006 Train R²: 0.2000 Test Loss: 0.0003 Test R²: 0.5779\n",
      "279 Train Loss: 0.0006 Train R²: 0.2193 Test Loss: 0.0003 Test R²: 0.5640\n",
      "280 Train Loss: 0.0005 Train R²: 0.3184 Test Loss: 0.0003 Test R²: 0.5430\n",
      "281 Train Loss: 0.0005 Train R²: 0.2449 Test Loss: 0.0003 Test R²: 0.5728\n",
      "282 Train Loss: 0.0006 Train R²: 0.1785 Test Loss: 0.0003 Test R²: 0.5891\n",
      "283 Train Loss: 0.0006 Train R²: 0.0789 Test Loss: 0.0003 Test R²: 0.5923\n",
      "284 Train Loss: 0.0007 Train R²: -0.0363 Test Loss: 0.0003 Test R²: 0.5917\n",
      "285 Train Loss: 0.0006 Train R²: 0.0835 Test Loss: 0.0003 Test R²: 0.5869\n",
      "286 Train Loss: 0.0006 Train R²: 0.1153 Test Loss: 0.0003 Test R²: 0.5744\n",
      "287 Train Loss: 0.0005 Train R²: 0.2403 Test Loss: 0.0003 Test R²: 0.5763\n",
      "288 Train Loss: 0.0005 Train R²: 0.3558 Test Loss: 0.0003 Test R²: 0.5188\n",
      "289 Train Loss: 0.0006 Train R²: 0.1912 Test Loss: 0.0003 Test R²: 0.5189\n",
      "290 Train Loss: 0.0005 Train R²: 0.2616 Test Loss: 0.0003 Test R²: 0.5722\n",
      "291 Train Loss: 0.0005 Train R²: 0.2806 Test Loss: 0.0003 Test R²: 0.5674\n",
      "292 Train Loss: 0.0005 Train R²: 0.2196 Test Loss: 0.0003 Test R²: 0.5718\n",
      "293 Train Loss: 0.0005 Train R²: 0.2597 Test Loss: 0.0003 Test R²: 0.5601\n",
      "294 Train Loss: 0.0005 Train R²: 0.2647 Test Loss: 0.0003 Test R²: 0.5648\n",
      "295 Train Loss: 0.0005 Train R²: 0.2592 Test Loss: 0.0003 Test R²: 0.5641\n",
      "296 Train Loss: 0.0005 Train R²: 0.2177 Test Loss: 0.0003 Test R²: 0.5892\n",
      "297 Train Loss: 0.0005 Train R²: 0.2464 Test Loss: 0.0002 Test R²: 0.6051\n",
      "298 Train Loss: 0.0006 Train R²: 0.2119 Test Loss: 0.0003 Test R²: 0.5939\n",
      "299 Train Loss: 0.0005 Train R²: 0.2351 Test Loss: 0.0002 Test R²: 0.6032\n",
      "300 Train Loss: 0.0005 Train R²: 0.2385 Test Loss: 0.0003 Test R²: 0.5955\n",
      "301 Train Loss: 0.0005 Train R²: 0.2917 Test Loss: 0.0003 Test R²: 0.5861\n",
      "302 Train Loss: 0.0005 Train R²: 0.3091 Test Loss: 0.0003 Test R²: 0.5691\n",
      "303 Train Loss: 0.0006 Train R²: 0.2085 Test Loss: 0.0003 Test R²: 0.5477\n",
      "304 Train Loss: 0.0005 Train R²: 0.2152 Test Loss: 0.0003 Test R²: 0.4629\n",
      "305 Train Loss: 0.0006 Train R²: 0.2139 Test Loss: 0.0003 Test R²: 0.5815\n",
      "306 Train Loss: 0.0006 Train R²: 0.2172 Test Loss: 0.0003 Test R²: 0.5921\n",
      "307 Train Loss: 0.0006 Train R²: 0.1738 Test Loss: 0.0003 Test R²: 0.5632\n",
      "308 Train Loss: 0.0005 Train R²: 0.2326 Test Loss: 0.0003 Test R²: 0.5657\n",
      "309 Train Loss: 0.0004 Train R²: 0.3810 Test Loss: 0.0003 Test R²: 0.5884\n",
      "310 Train Loss: 0.0005 Train R²: 0.2707 Test Loss: 0.0003 Test R²: 0.5897\n",
      "311 Train Loss: 0.0005 Train R²: 0.2741 Test Loss: 0.0003 Test R²: 0.5456\n",
      "312 Train Loss: 0.0006 Train R²: 0.1694 Test Loss: 0.0003 Test R²: 0.5756\n",
      "313 Train Loss: 0.0005 Train R²: 0.3075 Test Loss: 0.0003 Test R²: 0.5878\n",
      "314 Train Loss: 0.0006 Train R²: 0.2026 Test Loss: 0.0003 Test R²: 0.5715\n",
      "315 Train Loss: 0.0005 Train R²: 0.2841 Test Loss: 0.0003 Test R²: 0.5778\n",
      "316 Train Loss: 0.0005 Train R²: 0.3076 Test Loss: 0.0003 Test R²: 0.5829\n",
      "317 Train Loss: 0.0005 Train R²: 0.3317 Test Loss: 0.0003 Test R²: 0.5424\n",
      "318 Train Loss: 0.0005 Train R²: 0.3050 Test Loss: 0.0003 Test R²: 0.5986\n",
      "319 Train Loss: 0.0006 Train R²: 0.1520 Test Loss: 0.0003 Test R²: 0.5846\n",
      "320 Train Loss: 0.0005 Train R²: 0.3225 Test Loss: 0.0002 Test R²: 0.6022\n",
      "321 Train Loss: 0.0006 Train R²: 0.1461 Test Loss: 0.0002 Test R²: 0.6040\n",
      "322 Train Loss: 0.0004 Train R²: 0.3963 Test Loss: 0.0003 Test R²: 0.5964\n",
      "323 Train Loss: 0.0005 Train R²: 0.2534 Test Loss: 0.0002 Test R²: 0.6039\n",
      "324 Train Loss: 0.0005 Train R²: 0.2838 Test Loss: 0.0003 Test R²: 0.5807\n",
      "325 Train Loss: 0.0005 Train R²: 0.2970 Test Loss: 0.0003 Test R²: 0.5901\n",
      "326 Train Loss: 0.0005 Train R²: 0.2260 Test Loss: 0.0002 Test R²: 0.6031\n",
      "327 Train Loss: 0.0005 Train R²: 0.3318 Test Loss: 0.0002 Test R²: 0.6008\n",
      "328 Train Loss: 0.0005 Train R²: 0.2748 Test Loss: 0.0003 Test R²: 0.5968\n",
      "329 Train Loss: 0.0006 Train R²: 0.1992 Test Loss: 0.0003 Test R²: 0.5940\n",
      "330 Train Loss: 0.0006 Train R²: 0.2079 Test Loss: 0.0003 Test R²: 0.5793\n",
      "331 Train Loss: 0.0005 Train R²: 0.3282 Test Loss: 0.0003 Test R²: 0.5818\n",
      "332 Train Loss: 0.0004 Train R²: 0.4067 Test Loss: 0.0003 Test R²: 0.5958\n",
      "333 Train Loss: 0.0005 Train R²: 0.2853 Test Loss: 0.0002 Test R²: 0.6014\n",
      "334 Train Loss: 0.0004 Train R²: 0.3795 Test Loss: 0.0003 Test R²: 0.5865\n",
      "335 Train Loss: 0.0004 Train R²: 0.3684 Test Loss: 0.0003 Test R²: 0.5989\n",
      "336 Train Loss: 0.0005 Train R²: 0.3219 Test Loss: 0.0003 Test R²: 0.5874\n",
      "337 Train Loss: 0.0004 Train R²: 0.4269 Test Loss: 0.0003 Test R²: 0.5747\n",
      "338 Train Loss: 0.0005 Train R²: 0.2696 Test Loss: 0.0003 Test R²: 0.5567\n",
      "339 Train Loss: 0.0005 Train R²: 0.2531 Test Loss: 0.0003 Test R²: 0.5473\n",
      "340 Train Loss: 0.0005 Train R²: 0.2597 Test Loss: 0.0003 Test R²: 0.5724\n",
      "341 Train Loss: 0.0005 Train R²: 0.2972 Test Loss: 0.0003 Test R²: 0.5837\n",
      "342 Train Loss: 0.0006 Train R²: 0.1084 Test Loss: 0.0002 Test R²: 0.6089\n",
      "343 Train Loss: 0.0005 Train R²: 0.3093 Test Loss: 0.0002 Test R²: 0.6074\n",
      "344 Train Loss: 0.0005 Train R²: 0.2742 Test Loss: 0.0003 Test R²: 0.5891\n",
      "345 Train Loss: 0.0004 Train R²: 0.3694 Test Loss: 0.0003 Test R²: 0.4865\n",
      "346 Train Loss: 0.0005 Train R²: 0.2375 Test Loss: 0.0003 Test R²: 0.5446\n",
      "347 Train Loss: 0.0005 Train R²: 0.2965 Test Loss: 0.0003 Test R²: 0.5123\n",
      "348 Train Loss: 0.0005 Train R²: 0.3150 Test Loss: 0.0003 Test R²: 0.5875\n",
      "349 Train Loss: 0.0005 Train R²: 0.3529 Test Loss: 0.0003 Test R²: 0.5999\n",
      "350 Train Loss: 0.0006 Train R²: 0.2110 Test Loss: 0.0003 Test R²: 0.5835\n",
      "351 Train Loss: 0.0004 Train R²: 0.3624 Test Loss: 0.0003 Test R²: 0.5983\n",
      "352 Train Loss: 0.0004 Train R²: 0.4030 Test Loss: 0.0003 Test R²: 0.5493\n",
      "353 Train Loss: 0.0005 Train R²: 0.2759 Test Loss: 0.0002 Test R²: 0.6023\n",
      "354 Train Loss: 0.0004 Train R²: 0.3747 Test Loss: 0.0003 Test R²: 0.5555\n",
      "355 Train Loss: 0.0004 Train R²: 0.3872 Test Loss: 0.0003 Test R²: 0.5874\n",
      "356 Train Loss: 0.0005 Train R²: 0.2948 Test Loss: 0.0003 Test R²: 0.5084\n",
      "357 Train Loss: 0.0004 Train R²: 0.3968 Test Loss: 0.0003 Test R²: 0.5810\n",
      "358 Train Loss: 0.0005 Train R²: 0.2822 Test Loss: 0.0002 Test R²: 0.6096\n",
      "359 Train Loss: 0.0004 Train R²: 0.3738 Test Loss: 0.0003 Test R²: 0.5713\n",
      "360 Train Loss: 0.0005 Train R²: 0.3058 Test Loss: 0.0002 Test R²: 0.6031\n",
      "361 Train Loss: 0.0005 Train R²: 0.3416 Test Loss: 0.0003 Test R²: 0.5452\n",
      "362 Train Loss: 0.0005 Train R²: 0.2569 Test Loss: 0.0003 Test R²: 0.5709\n",
      "363 Train Loss: 0.0005 Train R²: 0.3253 Test Loss: 0.0003 Test R²: 0.5982\n",
      "364 Train Loss: 0.0004 Train R²: 0.4019 Test Loss: 0.0003 Test R²: 0.5970\n",
      "365 Train Loss: 0.0004 Train R²: 0.4264 Test Loss: 0.0002 Test R²: 0.6049\n",
      "366 Train Loss: 0.0004 Train R²: 0.3602 Test Loss: 0.0002 Test R²: 0.6016\n",
      "367 Train Loss: 0.0004 Train R²: 0.3953 Test Loss: 0.0002 Test R²: 0.6076\n",
      "368 Train Loss: 0.0004 Train R²: 0.4406 Test Loss: 0.0003 Test R²: 0.5961\n",
      "369 Train Loss: 0.0004 Train R²: 0.3667 Test Loss: 0.0002 Test R²: 0.6035\n",
      "370 Train Loss: 0.0005 Train R²: 0.3052 Test Loss: 0.0003 Test R²: 0.5862\n",
      "371 Train Loss: 0.0004 Train R²: 0.3966 Test Loss: 0.0002 Test R²: 0.6163\n",
      "372 Train Loss: 0.0005 Train R²: 0.3206 Test Loss: 0.0003 Test R²: 0.5991\n",
      "373 Train Loss: 0.0004 Train R²: 0.3960 Test Loss: 0.0003 Test R²: 0.5385\n",
      "374 Train Loss: 0.0005 Train R²: 0.3386 Test Loss: 0.0003 Test R²: 0.5801\n",
      "375 Train Loss: 0.0005 Train R²: 0.3175 Test Loss: 0.0003 Test R²: 0.5650\n",
      "376 Train Loss: 0.0004 Train R²: 0.3842 Test Loss: 0.0003 Test R²: 0.4513\n",
      "377 Train Loss: 0.0004 Train R²: 0.4398 Test Loss: 0.0003 Test R²: 0.5767\n",
      "378 Train Loss: 0.0005 Train R²: 0.3130 Test Loss: 0.0003 Test R²: 0.5620\n",
      "379 Train Loss: 0.0004 Train R²: 0.4227 Test Loss: 0.0003 Test R²: 0.5772\n",
      "380 Train Loss: 0.0004 Train R²: 0.4086 Test Loss: 0.0003 Test R²: 0.5694\n",
      "381 Train Loss: 0.0004 Train R²: 0.3867 Test Loss: 0.0003 Test R²: 0.5856\n",
      "382 Train Loss: 0.0004 Train R²: 0.4598 Test Loss: 0.0003 Test R²: 0.5877\n",
      "383 Train Loss: 0.0004 Train R²: 0.4015 Test Loss: 0.0003 Test R²: 0.5942\n",
      "384 Train Loss: 0.0004 Train R²: 0.4233 Test Loss: 0.0003 Test R²: 0.5836\n",
      "385 Train Loss: 0.0004 Train R²: 0.3818 Test Loss: 0.0003 Test R²: 0.5699\n",
      "386 Train Loss: 0.0005 Train R²: 0.3310 Test Loss: 0.0003 Test R²: 0.5846\n",
      "387 Train Loss: 0.0004 Train R²: 0.4080 Test Loss: 0.0003 Test R²: 0.5968\n",
      "388 Train Loss: 0.0004 Train R²: 0.4531 Test Loss: 0.0003 Test R²: 0.5849\n",
      "389 Train Loss: 0.0004 Train R²: 0.3970 Test Loss: 0.0003 Test R²: 0.5908\n",
      "390 Train Loss: 0.0005 Train R²: 0.3222 Test Loss: 0.0003 Test R²: 0.5664\n",
      "391 Train Loss: 0.0005 Train R²: 0.3388 Test Loss: 0.0003 Test R²: 0.4912\n",
      "392 Train Loss: 0.0005 Train R²: 0.3559 Test Loss: 0.0003 Test R²: 0.5689\n",
      "393 Train Loss: 0.0004 Train R²: 0.3856 Test Loss: 0.0003 Test R²: 0.5593\n",
      "394 Train Loss: 0.0004 Train R²: 0.4157 Test Loss: 0.0003 Test R²: 0.5854\n",
      "395 Train Loss: 0.0004 Train R²: 0.4309 Test Loss: 0.0003 Test R²: 0.5636\n",
      "396 Train Loss: 0.0004 Train R²: 0.3827 Test Loss: 0.0003 Test R²: 0.5898\n",
      "397 Train Loss: 0.0004 Train R²: 0.4062 Test Loss: 0.0003 Test R²: 0.5983\n",
      "398 Train Loss: 0.0004 Train R²: 0.4834 Test Loss: 0.0003 Test R²: 0.5909\n",
      "399 Train Loss: 0.0005 Train R²: 0.3161 Test Loss: 0.0003 Test R²: 0.5808\n",
      "400 Train Loss: 0.0004 Train R²: 0.3739 Test Loss: 0.0003 Test R²: 0.5592\n",
      "401 Train Loss: 0.0005 Train R²: 0.3563 Test Loss: 0.0003 Test R²: 0.4924\n",
      "402 Train Loss: 0.0004 Train R²: 0.4500 Test Loss: 0.0003 Test R²: 0.5957\n",
      "403 Train Loss: 0.0004 Train R²: 0.3999 Test Loss: 0.0002 Test R²: 0.6043\n",
      "404 Train Loss: 0.0004 Train R²: 0.4179 Test Loss: 0.0002 Test R²: 0.6050\n",
      "405 Train Loss: 0.0004 Train R²: 0.3783 Test Loss: 0.0003 Test R²: 0.5978\n",
      "406 Train Loss: 0.0004 Train R²: 0.4227 Test Loss: 0.0003 Test R²: 0.5782\n",
      "407 Train Loss: 0.0004 Train R²: 0.4136 Test Loss: 0.0002 Test R²: 0.6044\n",
      "408 Train Loss: 0.0004 Train R²: 0.4109 Test Loss: 0.0003 Test R²: 0.5655\n",
      "409 Train Loss: 0.0004 Train R²: 0.4216 Test Loss: 0.0003 Test R²: 0.5948\n",
      "410 Train Loss: 0.0004 Train R²: 0.3870 Test Loss: 0.0003 Test R²: 0.5882\n",
      "411 Train Loss: 0.0004 Train R²: 0.4053 Test Loss: 0.0002 Test R²: 0.6027\n",
      "412 Train Loss: 0.0005 Train R²: 0.3454 Test Loss: 0.0003 Test R²: 0.5974\n",
      "413 Train Loss: 0.0005 Train R²: 0.3319 Test Loss: 0.0003 Test R²: 0.4774\n",
      "414 Train Loss: 0.0004 Train R²: 0.3855 Test Loss: 0.0003 Test R²: 0.5946\n",
      "415 Train Loss: 0.0004 Train R²: 0.4104 Test Loss: 0.0003 Test R²: 0.5954\n",
      "416 Train Loss: 0.0004 Train R²: 0.3950 Test Loss: 0.0003 Test R²: 0.5792\n",
      "417 Train Loss: 0.0004 Train R²: 0.4509 Test Loss: 0.0003 Test R²: 0.5996\n",
      "418 Train Loss: 0.0004 Train R²: 0.3756 Test Loss: 0.0003 Test R²: 0.5999\n",
      "419 Train Loss: 0.0004 Train R²: 0.3709 Test Loss: 0.0002 Test R²: 0.6017\n",
      "420 Train Loss: 0.0004 Train R²: 0.4105 Test Loss: 0.0003 Test R²: 0.5907\n",
      "421 Train Loss: 0.0004 Train R²: 0.4833 Test Loss: 0.0003 Test R²: 0.5927\n",
      "422 Train Loss: 0.0004 Train R²: 0.4556 Test Loss: 0.0003 Test R²: 0.5603\n",
      "423 Train Loss: 0.0004 Train R²: 0.3876 Test Loss: 0.0003 Test R²: 0.5807\n",
      "424 Train Loss: 0.0004 Train R²: 0.3657 Test Loss: 0.0003 Test R²: 0.5505\n",
      "425 Train Loss: 0.0004 Train R²: 0.4030 Test Loss: 0.0002 Test R²: 0.6084\n",
      "426 Train Loss: 0.0004 Train R²: 0.4584 Test Loss: 0.0003 Test R²: 0.5995\n",
      "427 Train Loss: 0.0004 Train R²: 0.4285 Test Loss: 0.0003 Test R²: 0.5998\n",
      "428 Train Loss: 0.0005 Train R²: 0.3512 Test Loss: 0.0003 Test R²: 0.5850\n",
      "429 Train Loss: 0.0005 Train R²: 0.3441 Test Loss: 0.0003 Test R²: 0.5347\n",
      "430 Train Loss: 0.0004 Train R²: 0.3858 Test Loss: 0.0003 Test R²: 0.5621\n",
      "431 Train Loss: 0.0004 Train R²: 0.4495 Test Loss: 0.0003 Test R²: 0.5641\n",
      "432 Train Loss: 0.0004 Train R²: 0.4705 Test Loss: 0.0003 Test R²: 0.5708\n",
      "433 Train Loss: 0.0004 Train R²: 0.4488 Test Loss: 0.0003 Test R²: 0.5798\n",
      "434 Train Loss: 0.0004 Train R²: 0.4534 Test Loss: 0.0002 Test R²: 0.6008\n",
      "435 Train Loss: 0.0004 Train R²: 0.4157 Test Loss: 0.0002 Test R²: 0.6233\n",
      "436 Train Loss: 0.0004 Train R²: 0.4065 Test Loss: 0.0002 Test R²: 0.6224\n",
      "437 Train Loss: 0.0004 Train R²: 0.3965 Test Loss: 0.0002 Test R²: 0.6233\n",
      "438 Train Loss: 0.0004 Train R²: 0.4334 Test Loss: 0.0002 Test R²: 0.6021\n",
      "439 Train Loss: 0.0004 Train R²: 0.4379 Test Loss: 0.0003 Test R²: 0.5875\n",
      "440 Train Loss: 0.0004 Train R²: 0.4073 Test Loss: 0.0003 Test R²: 0.5219\n",
      "441 Train Loss: 0.0004 Train R²: 0.4822 Test Loss: 0.0003 Test R²: 0.5857\n",
      "442 Train Loss: 0.0004 Train R²: 0.4511 Test Loss: 0.0003 Test R²: 0.5954\n",
      "443 Train Loss: 0.0004 Train R²: 0.4605 Test Loss: 0.0002 Test R²: 0.6203\n",
      "444 Train Loss: 0.0004 Train R²: 0.4506 Test Loss: 0.0003 Test R²: 0.5962\n",
      "445 Train Loss: 0.0004 Train R²: 0.4327 Test Loss: 0.0003 Test R²: 0.5988\n",
      "446 Train Loss: 0.0004 Train R²: 0.4224 Test Loss: 0.0003 Test R²: 0.5889\n",
      "447 Train Loss: 0.0004 Train R²: 0.3967 Test Loss: 0.0003 Test R²: 0.5174\n",
      "448 Train Loss: 0.0003 Train R²: 0.5103 Test Loss: 0.0003 Test R²: 0.5543\n",
      "449 Train Loss: 0.0004 Train R²: 0.4703 Test Loss: 0.0003 Test R²: 0.5969\n",
      "450 Train Loss: 0.0004 Train R²: 0.4676 Test Loss: 0.0002 Test R²: 0.6091\n",
      "451 Train Loss: 0.0004 Train R²: 0.4967 Test Loss: 0.0002 Test R²: 0.6036\n",
      "452 Train Loss: 0.0004 Train R²: 0.4756 Test Loss: 0.0003 Test R²: 0.5903\n",
      "453 Train Loss: 0.0003 Train R²: 0.5125 Test Loss: 0.0003 Test R²: 0.5921\n",
      "454 Train Loss: 0.0004 Train R²: 0.4667 Test Loss: 0.0002 Test R²: 0.6010\n",
      "455 Train Loss: 0.0004 Train R²: 0.4737 Test Loss: 0.0002 Test R²: 0.6108\n",
      "456 Train Loss: 0.0004 Train R²: 0.4873 Test Loss: 0.0003 Test R²: 0.5652\n",
      "457 Train Loss: 0.0004 Train R²: 0.3727 Test Loss: 0.0002 Test R²: 0.6075\n",
      "458 Train Loss: 0.0004 Train R²: 0.4364 Test Loss: 0.0002 Test R²: 0.6213\n",
      "459 Train Loss: 0.0004 Train R²: 0.4673 Test Loss: 0.0003 Test R²: 0.5982\n",
      "460 Train Loss: 0.0004 Train R²: 0.4390 Test Loss: 0.0002 Test R²: 0.6069\n",
      "461 Train Loss: 0.0004 Train R²: 0.4854 Test Loss: 0.0002 Test R²: 0.6119\n",
      "462 Train Loss: 0.0003 Train R²: 0.5124 Test Loss: 0.0002 Test R²: 0.6069\n",
      "463 Train Loss: 0.0004 Train R²: 0.4611 Test Loss: 0.0003 Test R²: 0.5773\n",
      "464 Train Loss: 0.0004 Train R²: 0.4328 Test Loss: 0.0002 Test R²: 0.6034\n",
      "465 Train Loss: 0.0003 Train R²: 0.5352 Test Loss: 0.0003 Test R²: 0.5908\n",
      "466 Train Loss: 0.0004 Train R²: 0.4853 Test Loss: 0.0002 Test R²: 0.6003\n",
      "467 Train Loss: 0.0004 Train R²: 0.4581 Test Loss: 0.0002 Test R²: 0.6082\n",
      "468 Train Loss: 0.0004 Train R²: 0.4765 Test Loss: 0.0002 Test R²: 0.6086\n",
      "469 Train Loss: 0.0004 Train R²: 0.4523 Test Loss: 0.0003 Test R²: 0.5910\n",
      "470 Train Loss: 0.0004 Train R²: 0.5016 Test Loss: 0.0003 Test R²: 0.5708\n",
      "471 Train Loss: 0.0004 Train R²: 0.4976 Test Loss: 0.0002 Test R²: 0.6253\n",
      "472 Train Loss: 0.0004 Train R²: 0.4823 Test Loss: 0.0002 Test R²: 0.6099\n",
      "473 Train Loss: 0.0004 Train R²: 0.4931 Test Loss: 0.0003 Test R²: 0.5967\n",
      "474 Train Loss: 0.0003 Train R²: 0.5096 Test Loss: 0.0003 Test R²: 0.5917\n",
      "475 Train Loss: 0.0004 Train R²: 0.4497 Test Loss: 0.0003 Test R²: 0.5912\n",
      "476 Train Loss: 0.0004 Train R²: 0.4757 Test Loss: 0.0003 Test R²: 0.5936\n",
      "477 Train Loss: 0.0004 Train R²: 0.4636 Test Loss: 0.0003 Test R²: 0.5963\n",
      "478 Train Loss: 0.0004 Train R²: 0.4580 Test Loss: 0.0003 Test R²: 0.5968\n",
      "479 Train Loss: 0.0004 Train R²: 0.4751 Test Loss: 0.0003 Test R²: 0.5811\n",
      "480 Train Loss: 0.0004 Train R²: 0.3676 Test Loss: 0.0003 Test R²: 0.5852\n",
      "481 Train Loss: 0.0004 Train R²: 0.4462 Test Loss: 0.0003 Test R²: 0.5903\n",
      "482 Train Loss: 0.0003 Train R²: 0.5074 Test Loss: 0.0003 Test R²: 0.5798\n",
      "483 Train Loss: 0.0003 Train R²: 0.5458 Test Loss: 0.0002 Test R²: 0.6030\n",
      "484 Train Loss: 0.0004 Train R²: 0.4902 Test Loss: 0.0002 Test R²: 0.6135\n",
      "485 Train Loss: 0.0004 Train R²: 0.4666 Test Loss: 0.0002 Test R²: 0.6115\n",
      "486 Train Loss: 0.0004 Train R²: 0.4923 Test Loss: 0.0002 Test R²: 0.6186\n",
      "487 Train Loss: 0.0004 Train R²: 0.4749 Test Loss: 0.0002 Test R²: 0.6099\n",
      "488 Train Loss: 0.0004 Train R²: 0.4874 Test Loss: 0.0002 Test R²: 0.6139\n",
      "489 Train Loss: 0.0004 Train R²: 0.4647 Test Loss: 0.0003 Test R²: 0.5730\n",
      "490 Train Loss: 0.0004 Train R²: 0.4474 Test Loss: 0.0003 Test R²: 0.5885\n",
      "491 Train Loss: 0.0004 Train R²: 0.4648 Test Loss: 0.0003 Test R²: 0.5517\n",
      "492 Train Loss: 0.0003 Train R²: 0.5027 Test Loss: 0.0003 Test R²: 0.5281\n",
      "493 Train Loss: 0.0004 Train R²: 0.4831 Test Loss: 0.0003 Test R²: 0.5958\n",
      "494 Train Loss: 0.0004 Train R²: 0.4840 Test Loss: 0.0003 Test R²: 0.5832\n",
      "495 Train Loss: 0.0003 Train R²: 0.5227 Test Loss: 0.0003 Test R²: 0.5888\n",
      "496 Train Loss: 0.0003 Train R²: 0.5112 Test Loss: 0.0003 Test R²: 0.5797\n",
      "497 Train Loss: 0.0004 Train R²: 0.4860 Test Loss: 0.0003 Test R²: 0.5758\n",
      "498 Train Loss: 0.0003 Train R²: 0.5012 Test Loss: 0.0003 Test R²: 0.5524\n",
      "499 Train Loss: 0.0004 Train R²: 0.4882 Test Loss: 0.0003 Test R²: 0.5646\n",
      "500 Train Loss: 0.0003 Train R²: 0.5173 Test Loss: 0.0003 Test R²: 0.5776\n",
      "501 Train Loss: 0.0003 Train R²: 0.5760 Test Loss: 0.0003 Test R²: 0.5475\n",
      "502 Train Loss: 0.0004 Train R²: 0.4751 Test Loss: 0.0003 Test R²: 0.5767\n",
      "503 Train Loss: 0.0004 Train R²: 0.4725 Test Loss: 0.0003 Test R²: 0.5753\n",
      "504 Train Loss: 0.0004 Train R²: 0.4613 Test Loss: 0.0003 Test R²: 0.5831\n",
      "505 Train Loss: 0.0003 Train R²: 0.5363 Test Loss: 0.0003 Test R²: 0.5529\n",
      "506 Train Loss: 0.0004 Train R²: 0.4648 Test Loss: 0.0003 Test R²: 0.5738\n",
      "507 Train Loss: 0.0004 Train R²: 0.4905 Test Loss: 0.0003 Test R²: 0.5802\n",
      "508 Train Loss: 0.0004 Train R²: 0.4962 Test Loss: 0.0003 Test R²: 0.5879\n",
      "509 Train Loss: 0.0004 Train R²: 0.4344 Test Loss: 0.0003 Test R²: 0.5557\n",
      "510 Train Loss: 0.0004 Train R²: 0.4413 Test Loss: 0.0003 Test R²: 0.5512\n",
      "511 Train Loss: 0.0004 Train R²: 0.4865 Test Loss: 0.0003 Test R²: 0.5862\n",
      "512 Train Loss: 0.0003 Train R²: 0.5490 Test Loss: 0.0003 Test R²: 0.5697\n",
      "513 Train Loss: 0.0004 Train R²: 0.4396 Test Loss: 0.0003 Test R²: 0.5680\n",
      "514 Train Loss: 0.0003 Train R²: 0.5085 Test Loss: 0.0003 Test R²: 0.5906\n",
      "515 Train Loss: 0.0003 Train R²: 0.5328 Test Loss: 0.0002 Test R²: 0.6133\n",
      "516 Train Loss: 0.0003 Train R²: 0.5305 Test Loss: 0.0002 Test R²: 0.6311\n",
      "517 Train Loss: 0.0003 Train R²: 0.5425 Test Loss: 0.0002 Test R²: 0.6192\n",
      "518 Train Loss: 0.0004 Train R²: 0.4856 Test Loss: 0.0002 Test R²: 0.6128\n",
      "519 Train Loss: 0.0004 Train R²: 0.4791 Test Loss: 0.0003 Test R²: 0.5771\n",
      "520 Train Loss: 0.0003 Train R²: 0.5487 Test Loss: 0.0002 Test R²: 0.6168\n",
      "521 Train Loss: 0.0004 Train R²: 0.4839 Test Loss: 0.0003 Test R²: 0.5848\n",
      "522 Train Loss: 0.0004 Train R²: 0.4920 Test Loss: 0.0003 Test R²: 0.5728\n",
      "523 Train Loss: 0.0003 Train R²: 0.5174 Test Loss: 0.0003 Test R²: 0.5973\n",
      "524 Train Loss: 0.0004 Train R²: 0.4782 Test Loss: 0.0003 Test R²: 0.5630\n",
      "525 Train Loss: 0.0003 Train R²: 0.5496 Test Loss: 0.0003 Test R²: 0.5625\n",
      "526 Train Loss: 0.0003 Train R²: 0.5065 Test Loss: 0.0003 Test R²: 0.5871\n",
      "527 Train Loss: 0.0004 Train R²: 0.4819 Test Loss: 0.0002 Test R²: 0.6063\n",
      "528 Train Loss: 0.0003 Train R²: 0.5396 Test Loss: 0.0003 Test R²: 0.5924\n",
      "529 Train Loss: 0.0004 Train R²: 0.4785 Test Loss: 0.0003 Test R²: 0.5928\n",
      "530 Train Loss: 0.0003 Train R²: 0.5551 Test Loss: 0.0003 Test R²: 0.5212\n",
      "531 Train Loss: 0.0004 Train R²: 0.4998 Test Loss: 0.0003 Test R²: 0.5913\n",
      "532 Train Loss: 0.0003 Train R²: 0.5022 Test Loss: 0.0003 Test R²: 0.5861\n",
      "533 Train Loss: 0.0003 Train R²: 0.5465 Test Loss: 0.0003 Test R²: 0.5925\n",
      "534 Train Loss: 0.0004 Train R²: 0.4925 Test Loss: 0.0003 Test R²: 0.5988\n",
      "535 Train Loss: 0.0004 Train R²: 0.4997 Test Loss: 0.0003 Test R²: 0.5903\n",
      "536 Train Loss: 0.0004 Train R²: 0.4852 Test Loss: 0.0003 Test R²: 0.5719\n",
      "537 Train Loss: 0.0003 Train R²: 0.5384 Test Loss: 0.0003 Test R²: 0.5841\n",
      "538 Train Loss: 0.0004 Train R²: 0.4207 Test Loss: 0.0002 Test R²: 0.6188\n",
      "539 Train Loss: 0.0003 Train R²: 0.5026 Test Loss: 0.0003 Test R²: 0.5656\n",
      "540 Train Loss: 0.0004 Train R²: 0.4867 Test Loss: 0.0003 Test R²: 0.5765\n",
      "541 Train Loss: 0.0004 Train R²: 0.5005 Test Loss: 0.0003 Test R²: 0.5837\n",
      "542 Train Loss: 0.0003 Train R²: 0.5502 Test Loss: 0.0003 Test R²: 0.5640\n",
      "543 Train Loss: 0.0004 Train R²: 0.4786 Test Loss: 0.0003 Test R²: 0.5667\n",
      "544 Train Loss: 0.0004 Train R²: 0.5007 Test Loss: 0.0003 Test R²: 0.5040\n",
      "545 Train Loss: 0.0004 Train R²: 0.4677 Test Loss: 0.0003 Test R²: 0.5839\n",
      "546 Train Loss: 0.0004 Train R²: 0.4872 Test Loss: 0.0003 Test R²: 0.5734\n",
      "547 Train Loss: 0.0004 Train R²: 0.4894 Test Loss: 0.0003 Test R²: 0.5805\n",
      "548 Train Loss: 0.0003 Train R²: 0.5135 Test Loss: 0.0003 Test R²: 0.5782\n",
      "549 Train Loss: 0.0003 Train R²: 0.5027 Test Loss: 0.0003 Test R²: 0.5457\n",
      "550 Train Loss: 0.0004 Train R²: 0.4623 Test Loss: 0.0003 Test R²: 0.5882\n",
      "551 Train Loss: 0.0004 Train R²: 0.4732 Test Loss: 0.0003 Test R²: 0.5788\n",
      "552 Train Loss: 0.0003 Train R²: 0.5211 Test Loss: 0.0003 Test R²: 0.5615\n",
      "553 Train Loss: 0.0003 Train R²: 0.5378 Test Loss: 0.0003 Test R²: 0.5805\n",
      "554 Train Loss: 0.0004 Train R²: 0.5000 Test Loss: 0.0003 Test R²: 0.5578\n",
      "555 Train Loss: 0.0004 Train R²: 0.4730 Test Loss: 0.0003 Test R²: 0.5691\n",
      "556 Train Loss: 0.0003 Train R²: 0.5521 Test Loss: 0.0003 Test R²: 0.5595\n",
      "557 Train Loss: 0.0003 Train R²: 0.5210 Test Loss: 0.0003 Test R²: 0.5719\n",
      "558 Train Loss: 0.0003 Train R²: 0.5412 Test Loss: 0.0003 Test R²: 0.5867\n",
      "559 Train Loss: 0.0003 Train R²: 0.5150 Test Loss: 0.0003 Test R²: 0.5875\n",
      "560 Train Loss: 0.0003 Train R²: 0.5194 Test Loss: 0.0003 Test R²: 0.5857\n",
      "561 Train Loss: 0.0004 Train R²: 0.5026 Test Loss: 0.0003 Test R²: 0.5891\n",
      "562 Train Loss: 0.0003 Train R²: 0.5217 Test Loss: 0.0003 Test R²: 0.5827\n",
      "563 Train Loss: 0.0003 Train R²: 0.5194 Test Loss: 0.0003 Test R²: 0.5367\n",
      "564 Train Loss: 0.0003 Train R²: 0.5348 Test Loss: 0.0003 Test R²: 0.6003\n",
      "565 Train Loss: 0.0003 Train R²: 0.5136 Test Loss: 0.0003 Test R²: 0.5656\n",
      "566 Train Loss: 0.0003 Train R²: 0.5527 Test Loss: 0.0034 Test R²: -4.3735\n",
      "567 Train Loss: 0.0009 Train R²: -0.3227 Test Loss: 0.0003 Test R²: 0.5214\n",
      "568 Train Loss: 0.0004 Train R²: 0.4109 Test Loss: 0.0003 Test R²: 0.4510\n",
      "569 Train Loss: 0.0003 Train R²: 0.5034 Test Loss: 0.0003 Test R²: 0.5182\n",
      "570 Train Loss: 0.0004 Train R²: 0.4886 Test Loss: 0.0003 Test R²: 0.5221\n",
      "571 Train Loss: 0.0003 Train R²: 0.5147 Test Loss: 0.0003 Test R²: 0.5371\n",
      "572 Train Loss: 0.0004 Train R²: 0.5055 Test Loss: 0.0003 Test R²: 0.5906\n",
      "573 Train Loss: 0.0004 Train R²: 0.4968 Test Loss: 0.0003 Test R²: 0.5881\n",
      "574 Train Loss: 0.0003 Train R²: 0.5326 Test Loss: 0.0003 Test R²: 0.5384\n",
      "575 Train Loss: 0.0003 Train R²: 0.5336 Test Loss: 0.0003 Test R²: 0.5887\n",
      "576 Train Loss: 0.0004 Train R²: 0.4992 Test Loss: 0.0003 Test R²: 0.5600\n",
      "577 Train Loss: 0.0003 Train R²: 0.5245 Test Loss: 0.0003 Test R²: 0.5895\n",
      "578 Train Loss: 0.0003 Train R²: 0.5236 Test Loss: 0.0003 Test R²: 0.5903\n",
      "579 Train Loss: 0.0003 Train R²: 0.5323 Test Loss: 0.0003 Test R²: 0.5716\n",
      "580 Train Loss: 0.0003 Train R²: 0.5486 Test Loss: 0.0003 Test R²: 0.5947\n",
      "581 Train Loss: 0.0003 Train R²: 0.5026 Test Loss: 0.0003 Test R²: 0.5914\n",
      "582 Train Loss: 0.0003 Train R²: 0.5369 Test Loss: 0.0003 Test R²: 0.5718\n",
      "583 Train Loss: 0.0003 Train R²: 0.5481 Test Loss: 0.0003 Test R²: 0.5842\n",
      "584 Train Loss: 0.0004 Train R²: 0.4950 Test Loss: 0.0003 Test R²: 0.5907\n",
      "585 Train Loss: 0.0003 Train R²: 0.5034 Test Loss: 0.0003 Test R²: 0.6001\n",
      "586 Train Loss: 0.0003 Train R²: 0.5036 Test Loss: 0.0003 Test R²: 0.5907\n",
      "587 Train Loss: 0.0003 Train R²: 0.5487 Test Loss: 0.0003 Test R²: 0.5836\n",
      "588 Train Loss: 0.0004 Train R²: 0.5017 Test Loss: 0.0003 Test R²: 0.5663\n",
      "589 Train Loss: 0.0003 Train R²: 0.5424 Test Loss: 0.0003 Test R²: 0.5657\n",
      "590 Train Loss: 0.0004 Train R²: 0.4821 Test Loss: 0.0003 Test R²: 0.5786\n",
      "591 Train Loss: 0.0003 Train R²: 0.5563 Test Loss: 0.0003 Test R²: 0.5894\n",
      "592 Train Loss: 0.0003 Train R²: 0.5189 Test Loss: 0.0003 Test R²: 0.5551\n",
      "593 Train Loss: 0.0003 Train R²: 0.5261 Test Loss: 0.0003 Test R²: 0.5553\n",
      "594 Train Loss: 0.0003 Train R²: 0.5509 Test Loss: 0.0003 Test R²: 0.5565\n",
      "595 Train Loss: 0.0003 Train R²: 0.5763 Test Loss: 0.0003 Test R²: 0.5370\n",
      "596 Train Loss: 0.0004 Train R²: 0.5042 Test Loss: 0.0003 Test R²: 0.5731\n",
      "597 Train Loss: 0.0003 Train R²: 0.5601 Test Loss: 0.0003 Test R²: 0.5438\n",
      "598 Train Loss: 0.0003 Train R²: 0.5407 Test Loss: 0.0003 Test R²: 0.5825\n",
      "599 Train Loss: 0.0003 Train R²: 0.5321 Test Loss: 0.0003 Test R²: 0.4840\n"
     ]
    }
   ],
   "source": [
    "# training and evaluation loops\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "EPOCHS = 600\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    loss_list_train = []\n",
    "    pred_list_train = []  \n",
    "    true_list_train = []  \n",
    "    \n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "\n",
    "        loss = loss_function(output, data.y)\n",
    "        loss.backward()  \n",
    "        loss_list_train.append(loss.item())\n",
    "        optimizer.step()  \n",
    "        \n",
    "        # Store predictions \n",
    "        pred_list_train.extend(output.detach().cpu().numpy().flatten())\n",
    "        true_list_train.extend(data.y.cpu().numpy().flatten())\n",
    "    \n",
    "    # Calculate R² AFTER the loop\n",
    "    r2_train = r2_score(true_list_train, pred_list_train)\n",
    "        \n",
    "    loss_list_test = []\n",
    "    pred_list_test = []  \n",
    "    true_list_test = []  \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            output = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "\n",
    "            loss = loss_function(output, data.y)\n",
    "            loss_list_test.append(loss.item())\n",
    "     \n",
    "            # Store predictions - REPLACED\n",
    "            pred_list_test.extend(output.cpu().numpy().flatten())\n",
    "            true_list_test.extend(data.y.cpu().numpy().flatten())\n",
    "    \n",
    "    # Calculate R² AFTER the loop - NEW\n",
    "    r2_test = r2_score(true_list_test, pred_list_test)\n",
    "                \n",
    "    print(i, \"Train Loss: %.4f Train R²: %.4f Test Loss: %.4f Test R²: %.4f\"\n",
    "        % (np.mean(loss_list_train), r2_train, \n",
    "           np.mean(loss_list_test), r2_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
